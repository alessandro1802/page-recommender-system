https://en.wikipedia.org/wiki/Emotion_recognition_in_conversation
Emotion recognition in conversation (ERC) is a sub-field of emotion recognition, that focuses on mining human emotions from conversations or dialogues having two or more interlocutors.[1] The datasets in this field are usually derived from social platforms that allow free and plenty of samples, often containing multimodal data (i.e., some combination of textual, visual, and acoustic data).[2] Self- and inter-personal influences play critical role[3] in identifying some basic emotions, such as, fear, anger, joy, surprise, etc. The more fine grained the emotion labels are the harder it is to detect the correct emotion. ERC poses a number of challenges,[1] such as, conversational-context modeling, speaker-state modeling, presence of sarcasm in conversation, emotion shift across consecutive utterances of the same interlocutor. The task of ERC deals with detecting emotions expressed by the speakers in each utterance of the conversation. ERC depends on three primary factors â€“ the conversational context, interlocutors' mental state, and intent.[1] IEMOCAP,[4] SEMAINE,[5] DailyDialogue,[6] and MELD[7] are the four widely used datasets in ERC. Among these four datasets, MELD contains multiparty dialogues. Approaches to ERC consist of unsupervised, semi-unsupervised, and supervised[8] methods. Popular supervised methods include using or combining pre-defined features, recurrent neural networks [9] (DialogueRNN[10]), graph convolutional networks [11] (DialogueGCN [12]), and attention gated hierarchical memory network.[13] Most of the contemporary methods for ERC are deep learning based and rely on the idea of latent speaker-state modeling. Recently a new subtask of ERC has emerged that focuses on recognising emotion cause in conversation.[14] Methods to solve this task rely on language models-based question answering mechanism. RECCON[14] is one of the key datasets for this task.