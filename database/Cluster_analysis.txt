cluster analysis clustering task grouping set object way object group called cluster similar sense group cluster main task exploratory data analysis common technique statistical data analysis used many field including pattern recognition image analysis information retrieval bioinformatics data compression computer graphic machine learning cluster analysis one specific algorithm general task solved achieved various algorithm differ significantly understanding constitutes cluster efficiently find popular notion cluster include group small distance cluster member dense area data space interval particular statistical distribution clustering therefore formulated multi-objective optimization problem the appropriate clustering algorithm parameter setting including parameter distance function use density threshold number expected cluster depend individual data set intended use result cluster analysis automatic task iterative process knowledge discovery interactive multi-objective optimization involves trial failure often necessary modify data preprocessing model parameter result achieves desired property besides term clustering number term similar meaning including automatic classification numerical taxonomy botryology greek βότρυς grape typological analysis community detection the subtle difference often use result data mining resulting group matter interest automatic classification resulting discriminative power interest cluster analysis originated anthropology driver kroeber introduced psychology joseph zubin robert tryon famously used cattell beginning trait theory classification personality psychology the notion cluster precisely defined one reason many clustering algorithm there common denominator group data object however different researcher employ different cluster model cluster model different algorithm given the notion cluster found different algorithm varies significantly property understanding cluster model key understanding difference various algorithm typical cluster model include clustering essentially set cluster usually containing object data set additionally may specify relationship cluster example hierarchy cluster embedded clustering roughly distinguished there also finer distinction possible example listed clustering algorithm categorized based cluster model the following overview list prominent example clustering algorithm possibly published clustering algorithm not provide model cluster thus easily categorized overview algorithm explained wikipedia found list statistic algorithm there objectively correct clustering algorithm noted clustering eye beholder the appropriate clustering algorithm particular problem often need chosen experimentally unless mathematical reason prefer one cluster model another algorithm designed one kind model generally fail data set contains radically different kind model for example k-means find non-convex cluster connectivity-based clustering also known hierarchical clustering based core idea object related nearby object object farther away these algorithm connect object form cluster based distance cluster described largely maximum distance needed connect part cluster different distance different cluster form represented using dendrogram explains common name hierarchical clustering come algorithm provide single partitioning data set instead provide extensive hierarchy cluster merge certain distance dendrogram y-axis mark distance cluster merge object placed along x-axis cluster n't mix connectivity-based clustering whole family method differ way distance computed apart usual choice distance function user also need decide linkage criterion since cluster consists multiple object multiple candidate compute distance use popular choice known single-linkage clustering minimum object distance complete linkage clustering maximum object distance upgma wpgma unweighted weighted pair group method arithmetic mean also known average linkage clustering furthermore hierarchical clustering agglomerative starting single element aggregating cluster divisive starting complete data set dividing partition these method produce unique partitioning data set hierarchy user still need choose appropriate cluster they robust towards outlier either show additional cluster even cause cluster merge known chaining phenomenon particular single-linkage clustering general case complexity \displaystyle \mathcal agglomerative clustering \displaystyle \mathcal divisive clustering make slow large data set for special case optimal efficient method complexity \displaystyle \mathcal known slink single-linkage clink complete-linkage clustering single-linkage gaussian data cluster biggest cluster start fragmenting smaller part still connected second largest due single-link effect single-linkage density-based cluster cluster extracted contain single element since linkage clustering notion noise centroid-based clustering cluster represented central vector necessarily member data set when number cluster fixed k-means clustering give formal definition optimization problem find cluster center assign object nearest cluster center squared distance cluster minimized the optimization problem known np-hard thus common approach search approximate solution particularly well known approximate method lloyd algorithm often referred k-means algorithm although another algorithm introduced name however find local optimum commonly run multiple time different random initialization variation k-means often include optimization choosing best multiple run also restricting centroid member data set k-medoids choosing median k-medians clustering choosing initial center le randomly k-means++ allowing fuzzy cluster assignment fuzzy c-means most k-means-type algorithm require number cluster specified advance considered one biggest drawback algorithm furthermore algorithm prefer cluster approximately similar size always assign object nearest centroid this often lead incorrectly cut border cluster surprising since algorithm optimizes cluster center cluster border k-means number interesting theoretical property first partition data space structure known voronoi diagram second conceptually close nearest neighbor classification popular machine learning third seen variation model based clustering lloyd algorithm variation expectation-maximization algorithm model discussed k-means separate data voronoi cell assumes equal-sized cluster adequate k-means represent density-based cluster centroid-based clustering problem k-means k-medoids special case uncapacitated metric facility location problem canonical problem operation research computational geometry community basic facility location problem numerous variant model elaborate setting task find best warehouse location optimally service given set consumer one may view warehouse cluster centroid consumer location data clustered this make possible apply well-developed algorithmic solution facility location literature presently considered centroid-based clustering problem the clustering model closely related statistic based distribution model cluster easily defined object belonging likely distribution convenient property approach closely resembles way artificial data set generated sampling random object distribution while theoretical foundation method excellent suffer one key problem known overfitting unless constraint put model complexity complex model usually able explain data better make choosing appropriate model complexity inherently difficult one prominent method known gaussian mixture model using expectation-maximization algorithm here data set usually modeled fixed avoid overfitting number gaussian distribution initialized randomly whose parameter iteratively optimized better fit data set this converge local optimum multiple run may produce different result order obtain hard clustering object often assigned gaussian distribution likely belong soft clustering necessary distribution-based clustering produce complex model cluster capture correlation dependence attribute however algorithm put extra burden user many real data set may concisely defined mathematical model e.g assuming gaussian distribution rather strong assumption data gaussian-distributed data work well since us gaussians modelling cluster density-based cluster modeled using gaussian distribution density-based clustering cluster defined area higher density remainder data set object sparse area required separate cluster usually considered noise border point the popular density based clustering method dbscan contrast many newer method feature well-defined cluster model called density-reachability similar linkage based clustering based connecting point within certain distance threshold however connects point satisfy density criterion original variant defined minimum number object within radius cluster consists density-connected object form cluster arbitrary shape contrast many method plus object within object range another interesting property dbscan complexity fairly low requires linear number range query database discover essentially result deterministic core noise point border point run therefore need run multiple time optic generalization dbscan remove need choose appropriate value range parameter \displaystyle \varepsilon produce hierarchical result related linkage clustering deli-clu density-link-clustering combine idea single-linkage clustering optic eliminating \displaystyle \varepsilon parameter entirely offering performance improvement optic using r-tree index the key drawback dbscan optic expect kind density drop detect cluster border data set example overlapping gaussian distribution common use case artificial data cluster border produced algorithm often look arbitrary cluster density decrease continuously data set consisting mixture gaussians algorithm nearly always outperformed method clustering able precisely model kind data mean-shift clustering approach object moved densest area vicinity based kernel density estimation eventually object converge local maximum density similar k-means clustering density attractor serve representative data set mean-shift detect arbitrary-shaped cluster similar dbscan due expensive iterative procedure density estimation mean-shift usually slower dbscan k-means besides applicability mean-shift algorithm multidimensional data hindered unsmooth behaviour kernel density estimate result over-fragmentation cluster tail density-based clustering dbscan dbscan assumes cluster similar density may problem separating nearby cluster optic dbscan variant improving handling different density cluster the grid-based technique used multi-dimensional data set technique create grid structure comparison performed grid also known cell the grid-based technique fast low computational complexity there two type grid-based clustering method sting clique step involved grid-based clustering algorithm recent year considerable effort put improving performance existing algorithm among clarans birch with recent need process larger larger data set also known big data willingness trade semantic meaning generated cluster performance increasing this led development pre-clustering method canopy clustering process huge data set efficiently resulting cluster merely rough pre-partitioning data set analyze partition existing slower method k-means clustering for high-dimensional data many existing method fail due curse dimensionality render particular distance function problematic high-dimensional space this led new clustering algorithm high-dimensional data focus subspace clustering attribute used cluster model include relevant attribute cluster correlation clustering also look arbitrary rotated correlated subspace cluster modeled giving correlation attribute example clustering algorithm clique subclu idea density-based clustering method particular dbscan/optics family algorithm adapted subspace clustering hisc hierarchical subspace clustering dish correlation clustering hico hierarchical correlation clustering using correlation connectivity eric exploring hierarchical density-based correlation cluster several different clustering system based mutual information proposed one marina meilă variation information metric another provides hierarchical clustering using genetic algorithm wide range different fit-functions optimized including mutual information also belief propagation recent development computer science statistical physic led creation new type clustering algorithm evaluation validation clustering result difficult clustering popular approach involve internal evaluation clustering summarized single quality score external evaluation clustering compared existing ground truth classification manual evaluation human expert indirect evaluation evaluating utility clustering intended application internal evaluation measure suffer problem represent function seen clustering objective for example one could cluster data set silhouette coefficient except known efficient algorithm using internal measure evaluation one rather compare similarity optimization problem necessarily useful clustering external evaluation similar problem ground truth label would need cluster practical application usually label hand label reflect one possible partitioning data set imply exist different maybe even better clustering neither approach therefore ultimately judge actual quality clustering need human evaluation highly subjective nevertheless statistic quite informative identifying bad clustering one dismiss subjective human evaluation when clustering result evaluated based data clustered called internal evaluation these method usually assign best score algorithm produce cluster high similarity within cluster low similarity cluster one drawback using internal criterion cluster evaluation high score internal measure necessarily result effective information retrieval application additionally evaluation biased towards algorithm use cluster model for example k-means clustering naturally optimizes object distance distance-based internal criterion likely overrate resulting clustering therefore internal evaluation measure best suited get insight situation one algorithm performs better another shall imply one algorithm produce valid result another validity measured index depends claim kind structure exists data set algorithm designed kind model chance data set contains radically different set model evaluation measure radically different criterion for example k-means clustering find convex cluster many evaluation index assume convex cluster data set non-convex cluster neither use k-means evaluation criterion assumes convexity sound more dozen internal evaluation measure exist usually based intuition item cluster similar item different cluster for example following method used ass quality clustering algorithm based internal criterion external evaluation clustering result evaluated based data used clustering known class label external benchmark such benchmark consist set pre-classified item set often created expert human thus benchmark set thought gold standard evaluation these type evaluation method measure close clustering predetermined benchmark class however recently discussed whether adequate real data synthetic data set factual ground truth since class contain internal structure attribute present may allow separation cluster class may contain anomaly additionally knowledge discovery point view reproduction known knowledge may necessarily intended result special scenario constrained clustering meta information class label used already clustering process hold-out information evaluation purpose non-trivial number measure adapted variant used evaluate classification task place counting number time class correctly assigned single data point known true positive pair counting metric ass whether pair data point truly cluster predicted cluster internal evaluation several external evaluation measure exist example one issue rand index false positive false negative equally weighted this may undesirable characteristic clustering application the f-measure address concern citation needed chance-corrected adjusted rand index measure cluster tendency measure degree cluster exist data clustered may performed initial test attempting clustering one way compare data random data average random data cluster