deep learning also known deep structured learning part broader family machine learning method based artificial neural network representation learning learning supervised semi-supervised unsupervised deep-learning architecture deep neural network deep belief network deep reinforcement learning recurrent neural network convolutional neural network transformer applied field including computer vision speech recognition natural language processing machine translation bioinformatics drug design medical image analysis climate science material inspection board game program produced result comparable case surpassing human expert performance artificial neural network anns inspired information processing distributed communication node biological system anns various difference biological brain specifically artificial neural network tend static symbolic biological brain living organism dynamic plastic analogue the adjective deep deep learning refers use multiple layer network early work showed linear perceptron universal classifier network nonpolynomial activation function one hidden layer unbounded width deep learning modern variation concerned unbounded number layer bounded size permit practical application optimized implementation retaining theoretical universality mild condition deep learning layer also permitted heterogeneous deviate widely biologically informed connectionist model sake efficiency trainability understandability hence structured part deep learning class machine learning algorithm us multiple layer progressively extract higher-level feature raw input for example image processing lower layer may identify edge higher layer may identify concept relevant human digit letter face most modern deep learning model based artificial neural network specifically convolutional neural network cnn although also include propositional formula latent variable organized layer-wise deep generative model node deep belief network deep boltzmann machine deep learning level learns transform input data slightly abstract composite representation image recognition application raw input may matrix pixel first representational layer may abstract pixel encode edge second layer may compose encode arrangement edge third layer may encode nose eye fourth layer may recognize image contains face importantly deep learning process learn feature optimally place level this eliminate need hand-tuning example varying number layer layer size provide different degree abstraction the word deep deep learning refers number layer data transformed more precisely deep learning system substantial credit assignment path cap depth the cap chain transformation input output cap describe potentially causal connection input output for feedforward neural network depth cap network number hidden layer plus one output layer also parameterized for recurrent neural network signal may propagate layer cap depth potentially unlimited universally agreed-upon threshold depth divide shallow learning deep learning researcher agree deep learning involves cap depth higher cap depth shown universal approximator sense emulate function beyond layer add function approximator ability network deep model cap able extract better feature shallow model hence extra layer help learning feature effectively deep learning architecture constructed greedy layer-by-layer method deep learning help disentangle abstraction pick feature improve performance for supervised learning task deep learning method eliminate feature engineering translating data compact intermediate representation akin principal component derive layered structure remove redundancy representation deep learning algorithm applied unsupervised learning task this important benefit unlabeled data abundant labeled data example deep structure trained unsupervised manner deep belief network deep neural network generally interpreted term universal approximation theorem probabilistic inference the classic universal approximation theorem concern capacity feedforward neural network single hidden layer finite size approximate continuous function first proof published george cybenko sigmoid activation function generalised feed-forward multi-layer architecture kurt hornik recent work also showed universal approximation also hold non-bounded activation function rectified linear unit the universal approximation theorem deep neural network concern capacity network bounded width depth allowed grow proved width deep neural network relu activation strictly larger input dimension network approximate lebesgue integrable function width smaller equal input dimension deep neural network universal approximator the probabilistic interpretation derives field machine learning feature inference well optimization concept training testing related fitting generalization respectively more specifically probabilistic interpretation considers activation nonlinearity cumulative distribution function the probabilistic interpretation led introduction dropout regularizer neural network the probabilistic interpretation introduced researcher including hopfield widrow narendra popularized survey one bishop some source point frank rosenblatt developed explored basic ingredient deep learning system today described book principle neurodynamics perceptrons theory brain mechanism published cornell aeronautical laboratory inc. cornell university the first general working learning algorithm supervised deep feedforward multilayer perceptrons published alexey ivakhnenko lapa paper described deep network eight layer trained group method data handling other deep learning working architecture specifically built computer vision began neocognitron introduced kunihiko fukushima the term deep learning introduced machine learning community rina dechter artificial neural network igor aizenberg colleague context boolean threshold neuron yann lecun applied standard backpropagation algorithm around reverse mode automatic differentiation since deep neural network purpose recognizing handwritten zip code mail while algorithm worked training required day independently wei zhang applied backpropagation algorithm convolutional neural network simplified neocognitron keeping convolutional interconnection image feature layer last fully connected layer alphabet recognition also proposed implementation cnn optical computing system subsequently wei zhang modified model removing last fully connected layer applied medical image object segmentation breast cancer detection mammogram andr√© carvalho together mike fairhurst david bisset published experimental result multi-layer boolean neural network also known weightless neural network composed self-organising feature extraction neural network module soft followed multi-layer classification neural network module gsn independently trained each layer feature extraction module extracted feature growing complexity regarding previous layer brendan frey demonstrated possible train two day network containing six fully connected layer several hundred hidden unit using wake-sleep algorithm co-developed peter dayan hinton many factor contribute slow speed including vanishing gradient problem analyzed sepp hochreiter since sven behnke extended feed-forward hierarchical convolutional approach neural abstraction pyramid lateral backward connection order flexibly incorporate context decision iteratively resolve local ambiguity simpler model use task-specific handcrafted feature gabor filter support vector machine svms popular choice artificial neural network ann computational cost lack understanding brain wire biological network both shallow deep learning e.g. recurrent net anns explored many year these method never outperformed non-uniform internal-handcrafting gaussian mixture model/hidden markov model gmm-hmm technology based generative model speech trained discriminatively key difficulty analyzed including gradient diminishing weak temporal correlation structure neural predictive model additional difficulty lack training data limited computing power most speech recognition researcher moved away neural net pursue generative modeling exception sri international late funded government nsa darpa sri studied deep neural network speech speaker recognition the speaker recognition team led larry heck reported significant success deep neural network speech processing national institute standard technology speaker recognition evaluation the sri deep neural network deployed nuance verifier representing first major industrial application deep learning the principle elevating raw feature hand-crafted optimization first explored successfully architecture deep autoencoder raw spectrogram linear filter-bank feature late showing superiority mel-cepstral feature contain stage fixed transformation spectrogram the raw feature speech waveform later produced excellent larger-scale result many aspect speech recognition taken deep learning method called long short-term memory lstm recurrent neural network published hochreiter schmidhuber lstm rnns avoid vanishing gradient problem learn very deep learning task require memory event happened thousand discrete time step important speech lstm started become competitive traditional speech recognizers certain task later combined connectionist temporal classification ctc stack lstm rnns google speech recognition reportedly experienced dramatic performance jump ctc-trained lstm made available google voice search publication geoff hinton ruslan salakhutdinov osindero teh showed many-layered feedforward neural network could effectively pre-trained one layer time treating layer turn unsupervised restricted boltzmann machine fine-tuning using supervised backpropagation the paper referred learning deep belief net deep learning part state-of-the-art system various discipline particularly computer vision automatic speech recognition asr result commonly used evaluation set timit asr mnist image classification well range large-vocabulary speech recognition task steadily improved convolutional neural network cnns superseded asr ctc lstm successful computer vision the impact deep learning industry began early cnns already processed estimated check written according yann lecun industrial application deep learning large-scale speech recognition started around the nip workshop deep learning speech recognition motivated limitation deep generative model speech possibility given capable hardware large-scale data set deep neural net dnn might become practical believed pre-training dnns using generative model deep belief net dbn would overcome main difficulty neural net however discovered replacing pre-training large amount training data straightforward backpropagation using dnns large context-dependent output layer produced error rate dramatically lower then-state-of-the-art gaussian mixture model gmm /hidden markov model hmm also more-advanced generative model-based system the nature recognition error produced two type system characteristically different offering technical insight integrate deep learning existing highly efficient run-time speech decoding system deployed major speech recognition system analysis around contrasting gmm generative speech model vs. dnn model stimulated early industrial investment deep learning speech recognition eventually leading pervasive dominant use industry that analysis done comparable performance le error rate discriminative dnns generative model researcher extended deep learning timit large vocabulary speech recognition adopting large output layer dnn based context-dependent hmm state constructed decision tree advance hardware driven renewed interest deep learning nvidia involved called big bang deep learning deep-learning neural network trained nvidia graphic processing unit gpus that year andrew determined gpus could increase speed deep-learning system time particular gpus well-suited matrix/vector computation involved machine learning gpus speed training algorithm order magnitude reducing running time week day further specialized hardware algorithm optimization used efficient processing deep learning model team led george dahl merck molecular activity challenge using multi-task deep neural network predict biomolecular target one drug hochreiter group used deep learning detect off-target toxic effect environmental chemical nutrient household product drug data challenge nih fda ncats significant additional impact image object recognition felt although cnns trained backpropagation around decade gpu implementation nns year including cnns fast implementation cnns gpus needed progress computer vision approach achieved first time superhuman performance visual pattern recognition contest also icdar chinese handwriting contest may isbi image segmentation contest until cnns play major role computer vision conference june paper ciresan leading conference cvpr showed max-pooling cnns gpu dramatically improve many vision benchmark record october similar system krizhevsky large-scale imagenet competition significant margin shallow machine learning method november ciresan system also icpr contest analysis large medical image cancer detection following year also miccai grand challenge topic error rate imagenet task using deep learning reduced following similar trend large-scale speech recognition image classification extended challenging task generating description caption image often combination cnns lstms some researcher state october imagenet victory anchored start deep learning revolution transformed industry march yoshua bengio geoffrey hinton yann lecun awarded turing award conceptual engineering breakthrough made deep neural network critical component computing artificial neural network anns connectionist system computing system inspired biological neural network constitute animal brain such system learn progressively improve ability task considering example generally without task-specific programming for example image recognition might learn identify image contain cat analyzing example image manually labeled cat cat using analytic result identify cat image they found use application difficult express traditional computer algorithm using rule-based programming ann based collection connected unit called artificial neuron analogous biological neuron biological brain each connection synapse neuron transmit signal another neuron the receiving postsynaptic neuron process signal signal downstream neuron connected neuron may state generally represented real number typically neuron synapsis may also weight varies learning proceeds increase decrease strength signal sends downstream typically neuron organized layer different layer may perform different kind transformation input signal travel first input last output layer possibly traversing layer multiple time the original goal neural network approach solve problem way human brain would over time attention focused matching specific mental ability leading deviation biology backpropagation passing information reverse direction adjusting network reflect information neural network used variety task including computer vision speech recognition machine translation social network filtering playing board video game medical diagnosis neural network typically thousand million unit million connection despite number several order magnitude le number neuron human brain network perform many task level beyond human e.g. recognizing face playing deep neural network dnn artificial neural network ann multiple layer input output layer there different type neural network always consist component neuron synapsis weight bias function these component whole function similarly human brain trained like algorithm citation needed for example dnn trained recognize dog breed given image calculate probability dog image certain breed the user review result select probability network display certain threshold etc return proposed label each mathematical manipulation considered layer citation needed complex dnn many layer hence name deep network dnns model complex non-linear relationship dnn architecture generate compositional model object expressed layered composition primitive the extra layer enable composition feature lower layer potentially modeling complex data fewer unit similarly performing shallow network for instance proved sparse multivariate polynomial exponentially easier approximate dnns shallow network deep architecture include many variant basic approach each architecture found success specific domain always possible compare performance multiple architecture unless evaluated data set dnns typically feedforward network data flow input layer output layer without looping back first dnn creates map virtual neuron assigns random numerical value weight connection the weight input multiplied return output network accurately recognize particular pattern algorithm would adjust weight that way algorithm make certain parameter influential determines correct mathematical manipulation fully process data recurrent neural network rnns data flow direction used application language modeling long short-term memory particularly effective use convolutional deep neural network cnns used computer vision cnns also applied acoustic modeling automatic speech recognition asr anns many issue arise naively trained dnns two common issue overfitting computation time dnns prone overfitting added layer abstraction allow model rare dependency training data regularization method ivakhnenko unit pruning weight decay \displaystyle \ell -regularization sparsity \displaystyle \ell -regularization applied training combat overfitting alternatively dropout regularization randomly omits unit hidden layer training this help exclude rare dependency finally data augmented via method cropping rotating smaller training set increased size reduce chance overfitting dnns must consider many training parameter size number layer number unit per layer learning rate initial weight sweeping parameter space optimal parameter may feasible due cost time computational resource various trick batching computing gradient several training example rather individual example speed computation large processing capability many-core architecture gpus intel xeon phi produced significant speedup training suitability processing architecture matrix vector computation alternatively engineer may look type neural network straightforward convergent training algorithm cmac cerebellar model articulation controller one kind neural network n't require learning rate randomized initial weight cmac the training process guaranteed converge one step new batch data computational complexity training algorithm linear respect number neuron involved since advance machine learning algorithm computer hardware led efficient method training deep neural network contain many layer non-linear hidden unit large output layer graphic processing unit gpus often ai-specific enhancement displaced cpu dominant method training large-scale commercial cloud openai estimated hardware computation used largest deep learning project alexnet alphazero found increase amount computation required doubling-time trendline month special electronic circuit called deep learning processor designed speed deep learning algorithm deep learning processor include neural processing unit npus huawei cellphone cloud computing server tensor processing unit tpu google cloud platform cerebras system also built dedicated system handle large deep learning model based largest processor industry second-generation wafer scale engine atomically thin semiconductor considered promising energy-efficient deep learning hardware basic device structure used logic operation data storage marega published experiment large-area active channel material developing logic-in-memory device circuit based floating-gate field-effect transistor fgfets feldmann proposed integrated photonic hardware accelerator parallel convolutional processing the author identify two key advantage integrated photonics electronic counterpart massively parallel data transfer wavelength division multiplexing conjunction frequency comb extremely high data modulation speed their system execute trillion multiply-accumulate operation per second indicating potential integrated photonics data-heavy application large-scale automatic speech recognition first convincing successful case deep learning lstm rnns learn very deep learning task involve multi-second interval containing speech event separated thousand discrete time step one time step corresponds ms. lstm forget gate competitive traditional speech recognizers certain task the initial success speech recognition based small-scale recognition task based timit the data set contains speaker eight major dialect american english speaker read sentence it small size let many configuration tried more importantly timit task concern phone-sequence recognition unlike word-sequence recognition allows weak phone bigram language model this let strength acoustic modeling aspect speech recognition easily analyzed the error rate listed including early result measured percent phone error rate per summarized since the debut dnns speaker recognition late speech recognition around lstm around accelerated progress eight major area all major commercial speech recognition system e.g. microsoft cortana xbox skype translator amazon alexa google now apple siri baidu iflytek voice search range nuance speech product etc based deep learning common evaluation set image classification mnist database data set mnist composed handwritten digit includes training example test example timit small size let user test multiple configuration comprehensive list result set available deep learning-based image recognition become superhuman producing accurate result human contestant this first occurred recognition traffic sign recognition human face deep learning-trained vehicle interpret camera view another example facial dysmorphology novel analysis fdna used analyze case human malformation connected large database genetic syndrome closely related progress made image recognition increasing application deep learning technique various visual art task dnns proven capable example neural network used implementing language model since early lstm helped improve machine translation language modeling other key technique field negative sampling word embedding word embedding thought representational layer deep learning architecture transforms atomic word positional representation word relative word dataset position represented point vector space using word embedding rnn input layer allows network parse sentence phrase using effective compositional vector grammar compositional vector grammar thought probabilistic context free grammar pcfg implemented rnn recursive auto-encoders built atop word embeddings ass sentence similarity detect paraphrasing deep neural architecture provide best result constituency parsing sentiment analysis information retrieval spoken language understanding machine translation contextual entity linking writing style recognition text classification others recent development generalize word embedding sentence embedding google translate us large end-to-end long short-term memory lstm network google neural machine translation gnmt us example-based machine translation method system learns million example translates whole sentence time rather piece google translate support one hundred language the network encodes semantics sentence rather simply memorizing phrase-to-phrase translation us english intermediate language pair large percentage candidate drug fail win regulatory approval these failure caused insufficient efficacy on-target effect undesired interaction off-target effect unanticipated toxic effect research explored use deep learning predict biomolecular target off-targets toxic effect environmental chemical nutrient household product drug atomnet deep learning system structure-based rational drug design atomnet used predict novel candidate biomolecules disease target ebola virus multiple sclerosis graph neural network used first time predict various property molecule large toxicology data set generative neural network used produce molecule validated experimentally way mouse deep reinforcement learning used approximate value possible direct marketing action defined term rfm variable the estimated value function shown natural interpretation customer lifetime value recommendation system used deep learning extract meaningful feature latent factor model content-based music journal recommendation multi-view deep learning applied learning user preference multiple domain the model us hybrid collaborative content-based approach enhances recommendation multiple task autoencoder ann used bioinformatics predict gene ontology annotation gene-function relationship medical informatics deep learning used predict sleep quality based data wearable prediction health complication electronic health record data deep learning shown produce competitive result medical application cancer cell classification lesion detection organ segmentation image enhancement modern deep learning tool demonstrate high accuracy detecting various disease helpfulness use specialist improve diagnosis efficiency finding appropriate mobile audience mobile advertising always challenging since many data point must considered analyzed target segment created used serving server deep learning used interpret large many-dimensioned advertising datasets many data point collected request/serve/click internet advertising cycle this information form basis machine learning improve selection deep learning successfully applied inverse problem denoising super-resolution inpainting film colorization these application include learning method shrinkage field effective image restoration train image dataset deep image prior train image need restoration deep learning successfully applied financial fraud detection tax evasion detection anti-money laundering potentially impressive demonstration unsupervised learning prosecution financial crime required produce training data also note state art model automated financial crime detection existed quite time application deep learning referred dramatically perform much simpler theoretical model one yet implemented model sensor location heuristic simple any human detection financial crime slhsahdfc example the model work simple heuristic choosing get input data placing sensor place frequented large concentration wealth power simply identifying live human turn automated detection financial crime accomplished high accuracy high confidence level even better model shown extremely effective identifying crime large destructive egregious crime due effectiveness model highly likely application financial crime detection deep learning never able compete image generator turn imagination art operated powerful creates art image based simple instruction text model supported deep learning called stable diffusion went viral art image generating technology attracted increasing amount digital image lover time many image generator tool born ai-based image generator usually work technology quite easy create stunning cartoon effect automatic drawing expected detail the united state department defense applied deep learning train robot new task observation physic informed neural network used solve partial differential equation forward inverse problem data driven manner one example reconstructing fluid flow governed navier-stokes equation using physic informed neural network require often expensive mesh generation conventional cfd method relies image reconstruction reconstruction underlying image image-related measurement several work showed better superior performance deep learning method compared analytical method various application e.g. spectral imaging ultrasound imaging epigenetic clock for information see epigenetic clock epigenetic clock biochemical test used measure age galkin used deep neural network train epigenetic aging clock unprecedented accuracy using blood sample the clock us information cpg site predicts people certain condition older healthy control ibd frontotemporal dementia ovarian cancer obesity the aging clock planned released public use insilico medicine spinoff company deep longevity deep learning closely related class theory brain development specifically neocortical development proposed cognitive neuroscientist early these developmental theory instantiated computational model making predecessor deep learning system these developmental model share property various proposed learning dynamic brain e.g. wave nerve growth factor support self-organization somewhat analogous neural network utilized deep learning model like neocortex neural network employ hierarchy layered filter layer considers information prior layer operating environment pass output possibly original input layer this process yield self-organizing stack transducer well-tuned operating environment description stated ... infant brain seems organize influence wave so-called trophic-factors ... different region brain become connected sequentially one layer tissue maturing another whole brain mature variety approach used investigate plausibility deep learning model neurobiological perspective one hand several variant backpropagation algorithm proposed order increase processing realism other researcher argued unsupervised form deep learning based hierarchical generative model deep belief network may closer biological reality respect generative neural network model related neurobiological evidence sampling-based processing cerebral cortex although systematic comparison human brain organization neuronal encoding deep network yet established several analogy reported for example computation performed deep learning unit could similar actual neuron neural population similarly representation developed deep learning model similar measured primate visual system single-unit population level facebook lab performs task automatically tagging uploaded picture name people google deepmind technology developed system capable learning play atari video game using pixel data input demonstrated alphago system learned game well enough beat professional player google translate us neural network translate language covariant.ai launched focus integrating deep learning factory researcher the university texas austin developed machine learning framework called training agent manually via evaluative reinforcement tamer proposed new method robot computer program learn perform task interacting human instructor first developed tamer new algorithm called deep tamer later introduced collaboration u.s. army research laboratory arl researcher deep tamer used deep learning provide robot ability learn new task observation using deep tamer robot learned task human trainer watching video stream observing human perform task in-person the robot later practiced task help coaching trainer provided feedback good job bad job. deep learning attracted criticism comment case outside field computer science main criticism concern lack theory surrounding method learning common deep architecture implemented using well-understood gradient descent however theory surrounding algorithm contrastive divergence le clear citation needed e.g. doe converge fast what approximating deep learning method often looked black box confirmation done empirically rather theoretically others point deep learning looked step towards realizing strong all-encompassing solution despite power deep learning method still lack much functionality needed realizing goal entirely research psychologist gary marcus noted realistically deep learning part larger challenge building intelligent machine such technique lack way representing causal relationship ... obvious way performing logical inference also still long way integrating abstract knowledge information object typically used the powerful a.i system like watson ... use technique like deep learning one element complicated ensemble technique ranging statistical technique bayesian inference deductive reasoning reference idea artistic sensitivity might inherent relatively low level cognitive hierarchy published series graphic representation internal state deep layer neural network attempting discern within essentially random data image trained demonstrate visual appeal original research notice received well comment subject time frequently accessed article the guardian website some deep learning architecture display problematic behavior confidently classifying unrecognizable image belonging familiar category ordinary image misclassifying minuscule perturbation correctly classified image goertzel hypothesized behavior due limitation internal representation limitation would inhibit integration heterogeneous multi-component artificial general intelligence agi architecture these issue may possibly addressed deep learning architecture internally form state homologous image-grammar decomposition observed entity event learning grammar visual linguistic training data would equivalent restricting system commonsense reasoning operates concept term grammatical production rule basic goal human language acquisition artificial intelligence deep learning move lab world research experience show artificial neural network vulnerable hack deception identifying pattern system use function attacker modify input anns way ann find match human observer would recognize for example attacker make subtle change image ann find match even though image look human nothing like search target such manipulation termed adversarial attack. researcher used one ann doctor image trial error fashion identify another focal point thereby generate image deceived the modified image looked different human eye another group showed printout doctored image photographed successfully tricked image classification system one defense reverse image search possible fake image submitted site tineye find instance refinement search using part image identify image piece may taken another group showed certain psychedelic spectacle could fool facial recognition system thinking ordinary people celebrity potentially allowing one person impersonate another researcher added sticker stop sign caused ann misclassify anns however trained detect attempt deception potentially leading attacker defender arm race similar kind already defines malware defense industry anns trained defeat ann-based anti-malware software repeatedly attacking defense malware continually altered genetic algorithm tricked anti-malware retaining ability damage target another group demonstrated certain sound could make google now voice command system open particular web address hypothesized could serve stepping stone attack e.g. opening web page hosting drive-by malware data poisoning false data continually smuggled machine learning system training set prevent achieving mastery most deep learning system rely training verification data generated and/or annotated human argued medium philosophy low-paid clickwork e.g amazon mechanical turk regularly deployed purpose also implicit form human microwork often recognized the philosopher rainer m√ºhlhoff distinguishes five type machinic capture human microwork generate training data gamification embedding annotation computation task flow game trapping tracking e.g captchas image recognition click-tracking google search result page exploitation social motivation e.g tagging face facebook obtain labeled facial image information mining e.g leveraging quantified-self device activity tracker clickwork m√ºhlhoff argues commercial end-user application deep learning facebook face recognition system need training data stop ann trained rather continued demand human-generated verification data constantly calibrate update ann for purpose facebook introduced feature user automatically recognized image receive notification they choose whether like publicly labeled image tell facebook picture this user interface mechanism generate constant stream verification data train network real-time m√ºhlhoff argues involvement human user generate training verification data typical commercial end-user application deep learning system may referred human-aided artificial intelligence