data integration involves combining data residing different source providing user unified view this process becomes significant variety situation include commercial two similar company need merge database scientific combining research result different bioinformatics repository example domain data integration appears increasing frequency volume big data need share existing data explodes become focus extensive theoretical work numerous open problem remain unsolved data integration encourages collaboration internal well external user the data integrated must received heterogeneous database system transformed single coherent data store provides synchronous data across network file client common use data integration data mining analyzing extracting information existing database useful business information issue combining heterogeneous data source often referred information silo single query interface existed time early computer scientist began designing system interoperability heterogeneous database the first data integration system driven structured metadata designed university minnesota integrated public use microdata series ipums ipums used data warehousing approach extract transforms load data heterogeneous source unique view schema data different source become compatible making thousand population database interoperable ipums demonstrated feasibility large-scale data integration the data warehouse approach offer tightly coupled architecture data already physically reconciled single queryable repository usually take little time resolve query the data warehouse approach le feasible data set frequently updated requiring extract transform load etl process continuously re-executed synchronization difficulty also arise constructing data warehouse one query interface summary data source access full data this problem frequently emerges integrating several commercial query service like travel classified advertisement web application update trend data integration favored loose coupling data providing unified query-interface access real time data mediated schema see figure allows information retrieved directly original database this consistent soa approach popular era this approach relies mapping mediated schema schema original source translating query decomposed query match schema original database such mapping specified two way mapping entity mediated schema entity original source global-as-view gav approach mapping entity original source mediated schema local-as-view lav approach the latter approach requires sophisticated inference resolve query mediated schema make easier add new data source stable mediated schema update work data integration research concern semantic integration problem this problem address structuring architecture integration resolve semantic conflict heterogeneous data source for example two company merge database certain concept definition respective schema like earnings inevitably different meaning one database may mean profit dollar floating-point number might represent number sale integer common strategy resolution problem involves use ontology explicitly define schema term thus help resolve semantic conflict this approach represents ontology-based data integration hand problem combining research result different bioinformatics repository requires bench-marking similarity computed different data source single criterion positive predictive value this enables data source directly comparable integrated even nature experiment distinct update determined current data modeling method imparting data isolation every data architecture form island disparate data information silo this data isolation unintended artifact data modeling methodology result development disparate data model disparate data model instantiated database form disparate database enhanced data model methodology developed eliminate data isolation artifact promote development integrated data model one enhanced data modeling method recasts data model augmenting structural metadata form standardized data entity result recasting multiple data model set recast data model share one commonality relationship relate structural metadata common data model commonality relationship peer-to-peer type entity relationship relate standardized data entity multiple data model multiple data model contain standard data entity may participate commonality relationship when integrated data model instantiated database properly populated common set master data database integrated since data hub approach greater interest fully structured typically relational enterprise data warehouse since data lake approach risen level data hub see three search term popularity google trend these approach combine unstructured varied data one location necessarily require often complex master relational schema structure define data hub data integration play big role business regarding data collection used studying market converting raw data retrieved consumer coherent data something business try considering step take next organization frequently using data mining collecting information pattern database process help develop new business strategy increase business performance perform economic analysis efficiently compiling large amount data collect stored system form data integration adapted business intelligence improve chance success consider web application user query variety information city crime statistic weather hotel demographic etc. traditionally information must stored single database single schema but single enterprise would find information breadth somewhat difficult expensive collect even resource exist gather data would likely duplicate data existing crime database weather website census data data-integration solution may address problem considering external resource materialized view virtual mediated schema resulting virtual data integration this mean application-developers construct virtual schema—the mediated schema—to best model kind answer user want next design wrapper adapter data source crime database weather website these adapter simply transform local query result returned respective website database easily processed form data integration solution see figure when application-user query mediated schema data-integration solution transforms query appropriate query respective data source finally virtual database combine result query answer user query this solution offer convenience adding new source simply constructing adapter application software blade contrast etl system single database solution require manual integration entire new data set system the virtual etl solution leverage virtual mediated schema implement data harmonization whereby data copied designated master source defined target field field advanced data virtualization also built concept object-oriented modeling order construct virtual mediated schema virtual metadata repository using hub spoke architecture each data source disparate designed support reliable join data source therefore data virtualization well data federation depends upon accidental data commonality support combining data information disparate data set because lack data value commonality across data source return set may inaccurate incomplete impossible validate one solution recast disparate database integrate database without need etl the recast database support commonality constraint referential integrity may enforced database the recast database provide designed data access path data value commonality across database the theory data integration form subset database theory formalizes underlying concept problem first-order logic applying theory give indication feasibility difficulty data integration while definition may appear abstract sufficient generality accommodate manner integration system including include nested relational xml database treat database program connection particular database system oracle provided implementation-level technology jdbc studied theoretical level data integration system formally defined tuple \displaystyle \left\langle m\right\rangle \displaystyle global mediated schema \displaystyle heterogeneous set source schema \displaystyle mapping map query source global schema both \displaystyle \displaystyle expressed language alphabet composed symbol respective relation the mapping \displaystyle consists assertion query \displaystyle query \displaystyle when user pose query data integration system pose query \displaystyle mapping asserts connection element global schema source schema database schema defined set set one relation relational database the database corresponding source schema \displaystyle would comprise set set tuples heterogeneous data source called source database note single source database may actually represent collection disconnected database the database corresponding virtual mediated schema \displaystyle called global database the global database must satisfy mapping \displaystyle respect source database the legality mapping depends nature correspondence \displaystyle \displaystyle two popular way model correspondence exist global view gav local view lav gav system model global database set view \displaystyle case \displaystyle associate element \displaystyle query \displaystyle query processing becomes straightforward operation due well-defined association \displaystyle \displaystyle the burden complexity fall implementing mediator code instructing data integration system exactly retrieve element source database new source join system considerable effort may necessary update mediator thus gav approach appears preferable source seem unlikely change gav approach example data integration system system designer would first develop mediator city information source design global schema around mediator for example consider one source served weather website the designer would likely add corresponding element weather global schema then bulk effort concentrate writing proper mediator code transform predicate weather query weather website this effort become complex source also relates weather designer may need write code properly combine result two source hand lav source database modeled set view \displaystyle case \displaystyle associate element \displaystyle query \displaystyle here exact association \displaystyle \displaystyle longer well-defined illustrated next section burden determining retrieve element source placed query processor the benefit lav modeling new source added far le work gav system thus lav approach favored case mediated schema le stable likely change lav approach example data integration system system designer design global schema first simply input schema respective city information source consider one source serf weather website the designer would add corresponding element weather global schema none existed already then programmer write adapter wrapper website add schema description website result source schema the complexity adding new source move designer query processor the theory query processing data integration system commonly expressed using conjunctive query datalog purely declarative logic programming language one loosely think conjunctive query logical function applied relation database \displaystyle \displaystyle tuple set tuples substituted rule satisfies make true consider tuple part set answer query while formal language like datalog express query concisely without ambiguity common sql query count conjunctive query well term data integration query containment represents important property conjunctive query query \displaystyle contains another query \displaystyle denoted \displaystyle a\supset result applying \displaystyle subset result applying \displaystyle database the two query said equivalent resulting set equal database this important gav lav system user pose conjunctive query virtual schema represented set view materialized conjunctive query integration seek rewrite query represented view make result equivalent maximally contained user query this corresponds problem answering query using view aquv gav system system designer writes mediator code define query-rewriting each element user query corresponds substitution rule element global schema corresponds query source query processing simply expands subgoals user query according rule specified mediator thus resulting query likely equivalent while designer majority work beforehand gav system tsimmis involve simplifying mediator description process lav system query undergo radical process rewriting mediator exists align user query simple expansion strategy the integration system must execute search space possible query order find best rewrite the resulting rewrite may equivalent query maximally contained resulting tuples may incomplete update gqr algorithm leading query rewriting algorithm lav data integration system general complexity query rewriting np-complete space rewrite relatively small pose problem even integration system hundred source large-scale question science real world evidence global warming invasive specie spread resource depletion increasingly requiring collection disparate data set meta-analysis this type data integration especially challenging ecological environmental data metadata standard agreed upon many different data type produced field national science foundation initiative datanet intended make data integration easier scientist providing cyberinfrastructure setting standard the five funded datanet initiative dataone led william michener university new mexico the data conservancy led sayeed choudhury john hopkins university sead sustainable environment actionable data led margaret hedstrom university michigan datanet federation consortium led reagan moore university north carolina terra populus led steven ruggles university minnesota the research data alliance recently explored creating global data integration framework the openphacts project funded european union innovative medicine initiative built drug discovery platform linking datasets provider european bioinformatics institute royal society chemistry uniprot wikipathways drugbank