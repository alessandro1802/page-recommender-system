superintelligence hypothetical agent posse intelligence far surpassing brightest gifted human mind superintelligence may also refer property problem-solving system e.g. superintelligent language translator engineering assistant whether high-level intellectual competency embodied agent act world superintelligence may may created intelligence explosion associated technological singularity university oxford philosopher nick bostrom defines superintelligence intellect greatly exceeds cognitive performance human virtually domain interest the program fritz fall short superintelligence—even though much better human chess—because fritz outperform human task following hutter legg bostrom treat superintelligence general dominance goal-oriented behavior leaving open whether artificial human superintelligence would posse capacity intentionality chinese room argument first-person consciousness hard problem consciousness technological researcher disagree likely present-day human intelligence surpassed some argue advance artificial intelligence probably result general reasoning system lack human cognitive limitation others believe human evolve directly modify biology achieve radically greater intelligence number future study scenario combine element possibility suggesting human likely interface computer upload mind computer way enables substantial intelligence amplification some researcher believe superintelligence likely follow shortly development artificial general intelligence the first generally intelligent machine likely immediately hold enormous advantage least form mental capability including capacity perfect recall vastly superior knowledge base ability multitask way possible biological entity this may give opportunity to—either single new species—become much powerful human displace number scientist forecaster argue prioritizing early research possible benefit risk human machine cognitive enhancement potential social impact technology philosopher david chalmers argues artificial general intelligence likely path superhuman intelligence chalmers break claim argument achieve equivalence human intelligence extended surpass human intelligence amplified completely dominate human across arbitrary task concerning human-level equivalence chalmers argues human brain mechanical system therefore ought emulatable synthetic material also note human intelligence able biologically evolve making likely human engineer able recapitulate invention evolutionary algorithm particular able produce human-level concerning intelligence extension amplification chalmers argues new technology generally improved particularly likely invention assist designing new technology research strong produced sufficiently intelligent software would able reprogram improve feature called recursive self-improvement citation needed would even better improving could continue rapidly increasing cycle leading superintelligence this scenario known intelligence explosion such intelligence would limitation human intellect may able invent discover almost anything however also possible intelligence would conclude existential nihilism correct immediately destroy making kind superintelligence inherently unstable citation needed computer component already greatly surpass human performance speed bostrom writes biological neuron operate peak speed full seven order magnitude slower modern microprocessor ghz moreover neuron transmit spike signal across axon greater m/s whereas existing electronic processing core communicate optically speed light thus simplest example superintelligence may emulated human mind run much faster hardware brain human-like reasoner could think million time faster current human would dominant advantage reasoning task particularly one require haste long string action another advantage computer modularity size computational capacity increased non-human modified human brain could become much larger present-day human brain like many supercomputer bostrom also raise possibility collective superintelligence large enough number separate reasoning system communicated coordinated well enough could act aggregate far greater capability sub-agent there may also way qualitatively improve human reasoning decision-making human appear differ chimpanzee way think differ brain size speed human outperform non-human animal large part new enhanced reasoning capacity long-term planning language use see evolution human intelligence primate cognition possible improvement reasoning would similarly large impact make likelier agent built outperforms human fashion human outperform chimpanzee all advantage hold artificial superintelligence clear many hold biological superintelligence physiological constraint limit speed size biological brain many way inapplicable machine intelligence writer superintelligence devoted much attention superintelligent scenario carl sagan suggested advent caesarean section vitro fertilization may permit human evolve larger head resulting improvement via natural selection heritable component human intelligence contrast gerald crabtree argued decreased selection pressure resulting slow centuries-long reduction human intelligence process instead likely continue future there scientific consensus concerning either possibility case biological change would slow especially relative rate cultural change selective breeding nootropics epigenetic modulation genetic engineering could improve human intelligence rapidly bostrom writes come understand genetic component intelligence pre-implantation genetic diagnosis could used select embryo much point gain one embryo selected two larger gain e.g. point gained one embryo selected process iterated many generation gain could order magnitude greater bostrom suggests deriving new gamete embryonic stem cell could used iterate selection process rapidly well-organized society high-intelligence human sort could potentially achieve collective superintelligence alternatively collective intelligence might constructible better organizing human present level individual intelligence number writer suggested human civilization aspect e.g. internet economy coming function like global brain capacity far exceeding component agent systems-based superintelligence relies heavily artificial component however may qualify rather biology-based superorganism prediction market sometimes considered example working collective intelligence system consisting human assuming algorithm used inform decision final method intelligence amplification would directly enhance individual human opposed enhancing social reproductive dynamic this could achieved using nootropics somatic gene therapy brain–computer interface however bostrom express skepticism scalability first two approach argues designing superintelligent cyborg interface ai-complete problem most surveyed researcher expect machine eventually able rival human intelligence though little consensus likely happen conference attendee reported expecting machine able simulate learning every aspect human intelligence attendee expected happen sometime expected machine never reach milestone survey cited author may according microsoft academic search median year respondent expected machine carry human profession least well typical human assuming global catastrophe occurs confidence mean st. dev year confidence mean st. dev year confidence mean st. dev year these estimate exclude respondent said year would ever reach confidence said 'never confidence said 'never confidence respondent assigned median probability possibility machine superintelligence invented within year invention approximately human-level machine intelligence survey machine learning researcher published median year respondent expected high-level machine intelligence confidence citation needed the survey defined achievement high-level machine intelligence unaided machine accomplish every task better cheaply human worker bostrom expressed concern value superintelligence designed compared several proposal bostrom clarifies term instead implementing humanity coherent extrapolated volition one could try build goal morally right relying superior cognitive capacity figure action fit description call proposal moral rightness ... would also appear disadvantage relies notion morally right notoriously difficult concept one philosopher grappled since antiquity without yet attaining consensus analysis picking erroneous explication moral rightness could result outcome would morally wrong ... the path endowing moral concept might involve giving general linguistic ability comparable least normal human adult such general ability understand natural language could used understand meant morally right. could grasp meaning could search action fit ... one might try preserve basic idea model reducing demandingness focusing moral permissibility idea could let pursue humanity cev long act way morally impermissible responding bostrom santos-lang raised concern developer may attempt start single kind superintelligence suggested system rapidly become superintelligent may take unforeseen action out-compete humanity researcher argued way intelligence explosion self-improving could become powerful unstoppable human concerning human extinction scenario bostrom identifies superintelligence possible cause when create first superintelligent entity might make mistake give goal lead annihilate humankind assuming enormous intellectual advantage give power for example could mistakenly elevate subgoal status supergoal tell solve mathematical problem complies turning matter solar system giant calculating device process killing person asked question.in theory since superintelligent would able bring almost possible outcome thwart attempt prevent implementation goal many uncontrolled unintended consequence could arise could kill agent persuade change behavior block attempt interference eliezer yudkowsky illustrates instrumental convergence follows the hate love made atom use something else this present control problem build intelligent agent aid creator avoiding inadvertently building superintelligence harm creator the danger designing control right first time superintelligence may able seize power environment prevent human shutting since superintelligent likely ability fear death instead consider avoidable situation predicted avoided simply disabling power button potential control strategy include capability control limiting ability influence world motivational control building whose goal aligned human value bill hibbard advocate public education superintelligence public control development superintelligence